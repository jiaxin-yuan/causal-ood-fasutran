import torch
import numpy as np
import json
import os
import random
from typing import Dict, List, Any
import matplotlib.pyplot as plt
import seaborn as sns


def set_random_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def create_experiment_config(
    model_types: List[str] = None,
    data_config: Dict = None,
    training_config: Dict = None,
    adain_flag: bool=False
) -> Dict:
    """åˆ›å»ºå®Œæ•´çš„å®éªŒé…ç½®"""
    
    if model_types is None:
        model_types = ['transformer', 'graph_transformer', 'lstm']
    
    if data_config is None:
        data_config = {
            'use_synthetic': True,
            'num_samples': 1000,
            'seq_len': 50,
            'input_dim': 128,
            'num_domains': 3,
            'num_classes': 5,
            'train_domains': [0],
            'val_domains': [1],
            'test_domains': [2]
        }
    
    if training_config is None:
        training_config = {
            'batch_size': 32,
            'learning_rate': 1e-3,
            'weight_decay': 1e-5,
            'num_epochs': 50,
            'early_stopping_patience': 10,
            'seed': 42
        }
    
    # æ¨¡å‹é…ç½®
    model_configs = {}
    
    # ç¡®å®šè¾“å‡ºç»´åº¦ - å¯¹äºå›å½’ä»»åŠ¡æ˜¯1ï¼Œå¯¹äºåˆ†ç±»ä»»åŠ¡æ˜¯ç±»åˆ«æ•°
    output_dim = data_config.get('num_classes', 1)  # é»˜è®¤ä¸º1ï¼ˆå›å½’ä»»åŠ¡ï¼‰

    
    for model_type in model_types:
        if model_type == 'transformer':
            model_configs['transformer'] = {
                'type': 'transformer',
                'input_dim': data_config['input_dim'],
                'd_model': 256,
                'nhead': 8,
                'num_layers': 6,
                'output_dim': output_dim,
                'dropout': 0.1,
                'use_adain': adain_flag,
                'adain_prob': 0.8,
                **training_config
            }
        elif model_type == 'graph_transformer':
            model_configs['graph_transformer'] = {
                'type': 'graph_transformer',
                'input_dim': data_config['input_dim'],
                'hidden_dim': 256,
                'output_dim': output_dim,
                'num_heads': 8,
                'num_layers': 2,
                'dropout': 0.1,
                'use_adain': adain_flag,
                'adain_prob': 0.8,
                **training_config
            }
        elif model_type == 'lstm':
            model_configs['lstm'] = {
                'type': 'lstm',
                'input_dim': data_config['input_dim'],
                'hidden_dim': 256,
                'output_dim': output_dim,
                'num_layers': 2,
                'dropout': 0.1,
                'bidirectional': True,
                'use_adain': adain_flag,
                'adain_prob': 0.8,
                **training_config
            }
    
    return {
        'data_config': data_config,
        'model_configs': model_configs,
        'output_dir': 'results',
        'seed': training_config['seed']
    }


def plot_training_history(train_history: Dict, save_path: str = None):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # æŸå¤±å›¾
    axes[0].plot(train_history['train_losses'], label='è®­ç»ƒæŸå¤±', color='blue')
    axes[0].plot(train_history['val_losses'], label='éªŒè¯æŸå¤±', color='red')
    axes[0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('æŸå¤±')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # å‡†ç¡®ç‡å›¾
    axes[1].plot(train_history['train_accuracies'], label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')
    axes[1].plot(train_history['val_accuracies'], label='éªŒè¯å‡†ç¡®ç‡', color='red')
    axes[1].set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('å‡†ç¡®ç‡ (%)')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def analyze_domain_shift(features: np.ndarray, domains: np.ndarray, save_path: str = None):
    """åˆ†æå­¦ä¹ ç‰¹å¾ä¸­çš„é¢†åŸŸåç§»"""
    
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    
    # PCAåˆ†æ
    pca = PCA(n_components=2)
    features_pca = pca.fit_transform(features)
    
    # t-SNEåˆ†æ
    tsne = TSNE(n_components=2, random_state=42)
    features_tsne = tsne.fit_transform(features)
    
    # ç»˜å›¾
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    unique_domains = np.unique(domains)
    colors = plt.cm.Set1(np.linspace(0, 1, len(unique_domains)))
    
    # PCAå›¾
    for i, domain in enumerate(unique_domains):
        domain_mask = domains == domain
        axes[0].scatter(
            features_pca[domain_mask, 0], 
            features_pca[domain_mask, 1],
            c=[colors[i]], 
            label=f'é¢†åŸŸ {domain}',
            alpha=0.7
        )
    axes[0].set_title('ç‰¹å¾çš„PCAå¯è§†åŒ–')
    axes[0].set_xlabel('PC1')
    axes[0].set_ylabel('PC2')
    axes[0].legend()
    
    # t-SNEå›¾
    for i, domain in enumerate(unique_domains):
        domain_mask = domains == domain
        axes[1].scatter(
            features_tsne[domain_mask, 0], 
            features_tsne[domain_mask, 1],
            c=[colors[i]], 
            label=f'é¢†åŸŸ {domain}',
            alpha=0.7
        )
    axes[1].set_title('ç‰¹å¾çš„t-SNEå¯è§†åŒ–')
    axes[1].set_xlabel('t-SNE 1')
    axes[1].set_ylabel('t-SNE 2')
    axes[1].legend()
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def calculate_domain_statistics(features: np.ndarray, domains: np.ndarray) -> Dict:
    """è®¡ç®—é¢†åŸŸç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯"""
    
    unique_domains = np.unique(domains)
    domain_stats = {}
    
    for domain in unique_domains:
        domain_mask = domains == domain
        domain_features = features[domain_mask]
        
        domain_stats[f'domain_{domain}'] = {
            'mean': np.mean(domain_features, axis=0),
            'std': np.std(domain_features, axis=0),
            'samples': len(domain_features),
            'feature_dim': domain_features.shape[1]
        }
    
    # è®¡ç®—é¢†åŸŸè·ç¦»
    domain_distances = {}
    for i, domain1 in enumerate(unique_domains):
        for j, domain2 in enumerate(unique_domains):
            if i < j:
                mean1 = domain_stats[f'domain_{domain1}']['mean']
                mean2 = domain_stats[f'domain_{domain2}']['mean']
                
                # æ¬§å‡ é‡Œå¾—è·ç¦»
                euclidean_dist = np.linalg.norm(mean1 - mean2)
                
                # ä½™å¼¦è·ç¦»
                cosine_dist = 1 - np.dot(mean1, mean2) / (np.linalg.norm(mean1) * np.linalg.norm(mean2))
                
                domain_distances[f'{domain1}_to_{domain2}'] = {
                    'euclidean': euclidean_dist,
                    'cosine': cosine_dist
                }
    
    return {
        'domain_stats': domain_stats,
        'domain_distances': domain_distances
    }


def save_experiment_config(config: Dict, save_path: str):
    """å°†å®éªŒé…ç½®ä¿å­˜åˆ°æ–‡ä»¶"""
    
    with open(save_path, 'w') as f:
        json.dump(config, f, indent=2, default=str)


def load_experiment_config(config_path: str) -> Dict:
    """ä»æ–‡ä»¶åŠ è½½å®éªŒé…ç½®"""
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return config


def print_experiment_summary(results: Dict):
    """æ‰“å°å®éªŒç»“æœæ‘˜è¦"""
    
    print("\n" + "="*60)
    print("å®éªŒæ‘˜è¦")
    print("="*60)
    
    for model_name, result in results.items():
        metrics = result['metrics']
        print(f"\n{model_name.upper()}:")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›å½’ä»»åŠ¡
        if 'overall_mse' in metrics:
            # å›å½’ä»»åŠ¡æŒ‡æ ‡
            print(f"  æ•´ä½“MAE: {metrics.get('overall_mae', 'N/A'):.4f}")
            print(f"  æ•´ä½“RMSE: {metrics.get('overall_rmse', 'N/A'):.4f}")
            print(f"  æ•´ä½“RÂ²: {metrics.get('overall_r2', 'N/A'):.4f}")
            print(f"  é¢†åŸŸå·®è·: {metrics.get('domain_gap', 'N/A'):.4f}")
            print(f"  é¢†åŸŸæ•°é‡: {metrics.get('num_domains', 'N/A')}")
            
            # åŸå§‹å°ºåº¦æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'overall_mae_original' in metrics:
                print(f"  åŸå§‹å°ºåº¦MAE: {metrics['overall_mae_original']:.4f}")
                print(f"  åŸå§‹å°ºåº¦RMSE: {metrics.get('overall_rmse_original', 'N/A'):.4f}")
            
            print("  æ¯ä¸ªé¢†åŸŸçš„æ€§èƒ½:")
            for domain, domain_metric in metrics.get('domain_metrics', {}).items():
                mae = domain_metric.get('mae', 'N/A')
                rmse = domain_metric.get('rmse', 'N/A')
                samples = domain_metric.get('samples', 'N/A')
                print(f"    {domain}: MAE={mae:.4f}, RMSE={rmse:.4f}, æ ·æœ¬æ•°={samples}")
        
        elif 'overall_accuracy' in metrics:
            # åˆ†ç±»ä»»åŠ¡æŒ‡æ ‡ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
            print(f"  æ•´ä½“å‡†ç¡®ç‡: {metrics['overall_accuracy']:.4f}")
            print(f"  æ•´ä½“F1åˆ†æ•°: {metrics['overall_f1']:.4f}")
            print(f"  é¢†åŸŸå·®è·: {metrics['domain_gap']:.4f}")
            print(f"  é¢†åŸŸæ•°é‡: {metrics['num_domains']}")
            
            print("  æ¯ä¸ªé¢†åŸŸçš„æ€§èƒ½:")
            for domain, domain_metric in metrics['domain_metrics'].items():
                print(f"    {domain}: å‡†ç¡®ç‡={domain_metric['accuracy']:.4f}, F1={domain_metric['f1']:.4f}")
        
        else:
            print("  âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯„ä¼°æŒ‡æ ‡")
    
    # æ‰¾åˆ°æœ€ä½³æ¨¡å‹
    best_model = None
    best_score = float('inf')  # å¯¹äºå›å½’ä»»åŠ¡ï¼Œè¶Šå°è¶Šå¥½
    
    for model_name, result in results.items():
        metrics = result['metrics']
        
        # ä¼˜å…ˆä½¿ç”¨MAEä½œä¸ºè¯„ä¼°æŒ‡æ ‡
        if 'overall_mae' in metrics:
            score = metrics['overall_mae']
        elif 'overall_accuracy' in metrics:
            score = -metrics['overall_accuracy']  # åˆ†ç±»ä»»åŠ¡ï¼Œå‡†ç¡®ç‡è¶Šé«˜è¶Šå¥½ï¼Œæ‰€ä»¥ç”¨è´Ÿå€¼
        else:
            continue
            
        if score < best_score:
            best_score = score
            best_model = model_name
    
    if best_model:
        if 'overall_mae' in results[best_model]['metrics']:
            print(f"\nğŸ‰ æœ€ä½³æ¨¡å‹: {best_model} (MAE: {best_score:.4f})")
        else:
            print(f"\nğŸ‰ æœ€ä½³æ¨¡å‹: {best_model} (å‡†ç¡®ç‡: {-best_score:.4f})")
    else:
        print(f"\nâŒ æ— æ³•ç¡®å®šæœ€ä½³æ¨¡å‹")
    
    print("="*60) 
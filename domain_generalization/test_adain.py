#!/usr/bin/env python3
"""
AdaINåŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•AdaINå±‚çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. AdaINå±‚çš„æ­£ç¡®æ€§
2. æ¨¡å‹èƒ½å¦æ­£ç¡®ä½¿ç”¨AdaINå±‚
3. è®­ç»ƒè¿‡ç¨‹ä¸­çš„AdaINä½¿ç”¨
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from domain_generalization.models import AdaIN, TransformerModel, LSTMModel, GraphTransformer
from domain_generalization.data_loader import DataLoader
from domain_generalization.trainer import Trainer
import json


def test_adain_layer():
    """æµ‹è¯•AdaINå±‚çš„åŸºæœ¬åŠŸèƒ½"""
    print("="*50)
    print("æµ‹è¯•AdaINå±‚çš„åŸºæœ¬åŠŸèƒ½")
    print("="*50)
    
    adain = AdaIN(eps=1e-5)
    
    # æµ‹è¯•3Dè¾“å…¥ [batch_size, seq_len, feature_dim]
    batch_size, seq_len, feature_dim = 4, 10, 256
    z1 = torch.randn(batch_size, seq_len, feature_dim)
    z2 = torch.randn(batch_size, seq_len, feature_dim)
    
    print(f"è¾“å…¥å½¢çŠ¶: z1={z1.shape}, z2={z2.shape}")
    
    # åº”ç”¨AdaIN
    result = adain(z1, z2)
    print(f"è¾“å‡ºå½¢çŠ¶: {result.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert result.shape == z1.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {result.shape} != {z1.shape}"
    
    # éªŒè¯AdaINå…¬å¼
    # resultåº”è¯¥å…·æœ‰z2çš„ç»Ÿè®¡ç‰¹æ€§
    z1_mean = z1.mean(dim=-1, keepdim=True)
    z1_std = z1.std(dim=-1, keepdim=True) + 1e-5
    z2_mean = z2.mean(dim=-1, keepdim=True)
    z2_std = z2.std(dim=-1, keepdim=True) + 1e-5
    
    expected = z2_mean + z2_std * (z1 - z1_mean) / z1_std
    
    # æ£€æŸ¥ç»“æœæ˜¯å¦æ¥è¿‘é¢„æœŸ
    diff = torch.abs(result - expected).mean()
    print(f"AdaINç»“æœä¸é¢„æœŸçš„å¹³å‡å·®å¼‚: {diff.item():.8f}")
    assert diff < 1e-5, f"AdaINç»“æœä¸æ­£ç¡®ï¼Œå·®å¼‚è¿‡å¤§: {diff.item()}"
    
    print("âœ… AdaINå±‚åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•2Dè¾“å…¥ [batch_size, feature_dim]
    z1_2d = torch.randn(batch_size, feature_dim)
    z2_2d = torch.randn(batch_size, feature_dim)
    
    result_2d = adain(z1_2d, z2_2d)
    print(f"2Dè¾“å…¥æµ‹è¯•: {z1_2d.shape} -> {result_2d.shape}")
    assert result_2d.shape == z1_2d.shape, "2Dè¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"
    
    print("âœ… AdaINå±‚2Dè¾“å…¥æµ‹è¯•é€šè¿‡")


def test_models_with_adain():
    """æµ‹è¯•æ¨¡å‹èƒ½å¦æ­£ç¡®ä½¿ç”¨AdaINå±‚"""
    print("\n" + "="*50)
    print("æµ‹è¯•æ¨¡å‹AdaINåŠŸèƒ½")
    print("="*50)
    
    # é…ç½®å‚æ•°
    config = {
        'input_dim': 128,
        'd_model': 256,
        'nhead': 8,
        'num_layers': 2,
        'num_classes': 5,
        'dropout': 0.1,
        'use_adain': True,
        'hidden_dim': 256,
        'bidirectional': True
    }
    
    # æµ‹è¯•æ•°æ®
    batch_size, seq_len, input_dim = 4, 20, 128
    x = torch.randn(batch_size, seq_len, input_dim)
    style_x = torch.randn(batch_size, seq_len, input_dim)
    
    models = {
        'TransformerModel': TransformerModel(config),
        'LSTMModel': LSTMModel(config),
        'GraphTransformer': GraphTransformer(config)
    }
    
    for model_name, model in models.items():
        print(f"\næµ‹è¯• {model_name}:")
        
        # æµ‹è¯•ä¸ä½¿ç”¨AdaIN
        model.eval()
        with torch.no_grad():
            output1 = model(x)
            print(f"  ä¸ä½¿ç”¨AdaINè¾“å‡ºå½¢çŠ¶: {output1.shape}")
            
            # æµ‹è¯•ä½¿ç”¨AdaIN
            output2 = model(x, style_x=style_x)
            print(f"  ä½¿ç”¨AdaINè¾“å‡ºå½¢çŠ¶: {output2.shape}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶ä¸€è‡´
            assert output1.shape == output2.shape, f"{model_name} è¾“å‡ºå½¢çŠ¶ä¸ä¸€è‡´"
            
            # éªŒè¯AdaINç¡®å®äº§ç”Ÿäº†ä¸åŒçš„è¾“å‡º
            diff = torch.abs(output1 - output2).mean()
            print(f"  AdaINå‰åè¾“å‡ºå·®å¼‚: {diff.item():.6f}")
            
            # AdaINåº”è¯¥äº§ç”Ÿä¸åŒçš„è¾“å‡ºï¼ˆé™¤ééå¸¸å·§åˆï¼‰
            assert diff > 1e-6, f"{model_name} AdaINæ²¡æœ‰äº§ç”Ÿæ˜æ˜¾çš„è¾“å‡ºå·®å¼‚"
            
        print(f"  âœ… {model_name} AdaINåŠŸèƒ½æµ‹è¯•é€šè¿‡")


def test_trainer_with_adain():
    """æµ‹è¯•è®­ç»ƒå™¨çš„AdaINåŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•è®­ç»ƒå™¨AdaINåŠŸèƒ½")
    print("="*50)
    
    # åˆ›å»ºé…ç½®
    config = {
        'input_dim': 64,
        'd_model': 128,
        'nhead': 4,
        'num_layers': 2,
        'num_classes': 3,
        'dropout': 0.1,
        'use_adain': True,
        'adain_prob': 0.8,
        'learning_rate': 0.001,
        'weight_decay': 1e-5,
        'num_epochs': 2,  # åªæµ‹è¯•2ä¸ªepoch
        'batch_size': 16,
        'early_stopping_patience': 5
    }
    
    # åˆ›å»ºåˆæˆæ•°æ®
    data_loader = DataLoader(config)
    synthetic_data, synthetic_labels, synthetic_domains = data_loader.generate_synthetic_data(
        num_samples=100,  # å°æ•°æ®é›†ç”¨äºæµ‹è¯•
        seq_len=20,
        input_dim=config['input_dim'],
        num_domains=3,
        num_classes=config['num_classes']
    )
    
    # åˆ†å‰²æ•°æ®
    train_data, val_data, test_data = data_loader.split_data_by_domain(
        synthetic_data, synthetic_labels, synthetic_domains,
        train_domains=[0, 1],
        val_domains=[0, 1],
        test_domains=[2]
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = data_loader.create_dataloaders(
        train_data, val_data, test_data
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = TransformerModel(config)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(model, config)
    trainer.model_name = "AdaIN_Test"
    
    print(f"AdaINé…ç½®: å¯ç”¨={trainer.use_adain}, æ¦‚ç‡={trainer.adain_prob}")
    
    # è¿›è¡Œç®€çŸ­çš„è®­ç»ƒæµ‹è¯•
    print("\nå¼€å§‹è®­ç»ƒæµ‹è¯•...")
    try:
        results = trainer.train(train_loader, val_loader)
        print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯æŸå¤±: {results['best_val_loss']:.6f}")
        print("âœ… è®­ç»ƒå™¨AdaINåŠŸèƒ½æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå™¨AdaINåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        raise


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹AdaINåŠŸèƒ½æµ‹è¯•")
    print("="*80)
    
    try:
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(42)
        np.random.seed(42)
        
        # è¿è¡Œæµ‹è¯•
        test_adain_layer()
        test_models_with_adain()
        test_trainer_with_adain()
        
        print("\n" + "="*80)
        print("ğŸ‰ æ‰€æœ‰AdaINåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("="*80)
        
        # æ˜¾ç¤ºAdaINåŠŸèƒ½è¯´æ˜
        print("\nğŸ“ AdaINåŠŸèƒ½è¯´æ˜:")
        print("1. AdaIN (Adaptive Instance Normalization) å·²æˆåŠŸé›†æˆåˆ°æ‰€æœ‰3ä¸ªæ¨¡å‹ä¸­")
        print("2. å…¬å¼: AdaIN(z1,z2) = mean(z2) + std(z2) * (z1 - mean(z1)) / std(z1)")
        print("3. z1 = encoder(x1) - åŸå§‹è¾“å…¥çš„ç¼–ç ")
        print("4. z2 = encoder(x2) - ä»å…¶ä»–åŸŸéšæœºé‡‡æ ·çš„è¾“å…¥ç¼–ç ")
        print("5. è®­ç»ƒæ—¶ä¼šä»¥æŒ‡å®šæ¦‚ç‡ä½¿ç”¨AdaINè¿›è¡ŒåŸŸé£æ ¼è½¬æ¢")
        print("6. å¯é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„ 'use_adain' å’Œ 'adain_prob' å‚æ•°æ§åˆ¶")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 